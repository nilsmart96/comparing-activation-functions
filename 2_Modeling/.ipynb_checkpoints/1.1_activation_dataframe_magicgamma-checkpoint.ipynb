{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from livelossplot import PlotLossesKeras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# set random seed globally\n",
    "my_seed = 21\n",
    "from numpy.random import seed\n",
    "seed(my_seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(my_seed) \n",
    "# tensorflow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC Gamma Telescope Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19020 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fLength    fWidth   fSize   fConc  fConc1     fAsym   fM3Long  \\\n",
       "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
       "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
       "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
       "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
       "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
       "...         ...       ...     ...     ...     ...       ...       ...   \n",
       "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
       "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
       "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
       "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
       "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
       "\n",
       "       fM3Trans   fAlpha     fDist class  \n",
       "0       -8.2027  40.0920   81.8828     g  \n",
       "1       -9.9574   6.3609  205.2610     g  \n",
       "2      -45.2160  76.9600  256.7880     g  \n",
       "3       -7.1513  10.4490  116.7370     g  \n",
       "4       21.8393   4.6480  356.4620     g  \n",
       "...         ...      ...       ...   ...  \n",
       "19015    2.8766   2.4229  106.8258     h  \n",
       "19016   -2.9632  86.7975  247.4560     h  \n",
       "19017   -9.4662  30.2987  256.5166     h  \n",
       "19018  -63.8389  84.6874  408.3166     h  \n",
       "19019   31.4755  52.7310  272.3174     h  \n",
       "\n",
       "[19020 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataframe from https://archive.ics.uci.edu/ml/datasets/magic+gamma+telescope\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data',\n",
    "                 names = ['fLength','fWidth','fSize','fConc','fConc1','fAsym','fM3Long','fM3Trans','fAlpha','fDist','class'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSet (dataframe, test_data_fraction):\n",
    "    # encoding the target column\n",
    "    le = LabelEncoder()\n",
    "    label = le.fit_transform(df['class'])\n",
    "    label\n",
    "\n",
    "    encoded_df = df.copy()\n",
    "    encoded_df.drop(\"class\", axis=1, inplace=True)\n",
    "    encoded_df[\"class\"] = label\n",
    "\n",
    "    # Set the total number of classes\n",
    "    nb_classes = len(encoded_df['class'].unique())\n",
    "\n",
    "    # Creating target and features\n",
    "    X = encoded_df.drop(['class'], axis=1)\n",
    "    y = encoded_df['class']\n",
    "\n",
    "    # scale the variables\n",
    "    sc = StandardScaler() \n",
    "    X_scaled = sc.fit_transform(X)\n",
    "\n",
    "    # Split into train and test set and normalize data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, test_size = test_data_fraction,stratify=y) #, random_state = 0)\n",
    "\n",
    "\n",
    "    return encoded_df, nb_classes, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "class CustomWeight(tf.keras.initializers.Initializer):\n",
    "    def __init__(self):\n",
    "        print('gg')\n",
    "    def constant_weight(self,num):\n",
    "        return tf.keras.initializers.Constant(num)\n",
    "    \n",
    "    def normal_weight(self,mean,stddev):\n",
    "        return tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "\n",
    "\n",
    "def buildSequentialModel(hidden_layers_activation, first_layer_node_count, dropout_fraction, nb_classes,weight_class, wt_init, bias_init):\n",
    "    # Build a Sequential Model.\n",
    "    model = Sequential()\n",
    "    # model.add(Flatten(input_shape=(28, 28)))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(first_layer_node_count, kernel_initializer=weight_class.constant_weight(wt_init), activation=hidden_layers_activation,bias_initializer=weight_class.constant_weight(bias_init)))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    model.add(Dense(first_layer_node_count*0.8, kernel_initializer=weight_class.constant_weight(wt_init), activation=hidden_layers_activation,bias_initializer=weight_class.constant_weight(bias_init)))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    model.add(Dense(first_layer_node_count*0.6, kernel_initializer=weight_class.constant_weight(2.2), activation=hidden_layers_activation,bias_initializer=weight_class.constant_weight(bias_init)))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(nb_classes, activation=hidden_layers_activation, kernel_initializer=weight_class.constant_weight(2.2), bias_initializer=weight_class.constant_weight(bias_init)))\n",
    "   \n",
    "    return model\n",
    "\n",
    "\n",
    "''' def reset_weights(model):\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.Model): #if you're using a model as a layer\n",
    "            reset_weights(layer) #apply function recursively\n",
    "            continue\n",
    "\n",
    "        #where are the initializers?\n",
    "        if hasattr(layer, 'cell'):\n",
    "            init_container = layer.cell\n",
    "        else:\n",
    "            init_container = layer\n",
    "\n",
    "        for key, initializer in init_container.__dict__.items():\n",
    "            if \"initializer\" not in key: #is this item an initializer?\n",
    "                  continue #if no, skip it\n",
    "\n",
    "            # find the corresponding variable, like the kernel or the bias\n",
    "            if key == 'recurrent_initializer': #special case check\n",
    "                var = getattr(init_container, 'recurrent_kernel')\n",
    "            else:\n",
    "                var = getattr(init_container, key.replace(\"_initializer\", \"\"))\n",
    "\n",
    "            var.assign(initializer(var.shape, var.dtype))\n",
    "            #use the initializer '''\n",
    "\n",
    "\n",
    "def Study_Activation_Functions(hidden_layers_activation, first_layer_node_count, dropout_fraction, classes, X_train, X_test, y_train, y_test,weight_class, wt_init, bias_init):\n",
    "    \n",
    "    # instantiate model\n",
    "    model = buildSequentialModel(hidden_layers_activation, first_layer_node_count, dropout_fraction, classes,weight_class, wt_init, bias_init)\n",
    "    # compile model\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=50, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)[1] \n",
    "\n",
    "    predicted_classes = np.argmax(model.predict(X_test), axis=-1)\n",
    "    correct_indices = np.nonzero(predicted_classes == y_test.values)[0]\n",
    "    incorrect_indices = np.nonzero(predicted_classes != y_test.values)[0]\n",
    "\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataframe = (19020, 11)\n",
      "classes in dataset = 2\n",
      "X_train.shape = (15216, 10)\n",
      "X_test.shape = (3804, 10)\n",
      "y_train.shape = (15216,)\n",
      "y_test.shape = (3804,)\n",
      "\n",
      "encoded_dataframe shown below:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19020 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fLength    fWidth   fSize   fConc  fConc1     fAsym   fM3Long  \\\n",
       "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
       "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
       "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
       "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
       "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
       "...         ...       ...     ...     ...     ...       ...       ...   \n",
       "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
       "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
       "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
       "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
       "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
       "\n",
       "       fM3Trans   fAlpha     fDist  class  \n",
       "0       -8.2027  40.0920   81.8828      0  \n",
       "1       -9.9574   6.3609  205.2610      0  \n",
       "2      -45.2160  76.9600  256.7880      0  \n",
       "3       -7.1513  10.4490  116.7370      0  \n",
       "4       21.8393   4.6480  356.4620      0  \n",
       "...         ...      ...       ...    ...  \n",
       "19015    2.8766   2.4229  106.8258      1  \n",
       "19016   -2.9632  86.7975  247.4560      1  \n",
       "19017   -9.4662  30.2987  256.5166      1  \n",
       "19018  -63.8389  84.6874  408.3166      1  \n",
       "19019   31.4755  52.7310  272.3174      1  \n",
       "\n",
       "[19020 rows x 11 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build dataset on our dataframe\n",
    "encoded_dataframe, classes, Train_FEATURE_matrix, Test_FEATURE_matrix, Train_TARGET_matrix, Test_TARGET_matrix = buildDataSet (df, 0.2)\n",
    "\n",
    "print(f\"shape of dataframe = {encoded_dataframe.shape}\")\n",
    "print(f\"classes in dataset = {classes}\")\n",
    "print(f\"X_train.shape = {Train_FEATURE_matrix.shape}\")\n",
    "print(f\"X_test.shape = {Test_FEATURE_matrix.shape}\")\n",
    "print(f\"y_train.shape = {Train_TARGET_matrix.shape}\")\n",
    "print(f\"y_test.shape = {Test_TARGET_matrix.shape}\")\n",
    "print(\"\")\n",
    "print(\"encoded_dataframe shown below:\")\n",
    "encoded_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional Activation Functions to test\n",
    "\n",
    "- Logistic regression hypothesis (Sigmoid)\n",
    "- Hyperbolic Tangent (tanh) # rescaled sigmoid to (-1, +1)\n",
    "- Rectified Linear Unit (ReLU)\n",
    "- Gaussian Error Linear Unit (GELU) # smoothed ReLU\n",
    "- Normalized Exponential Function (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gg\n",
      "143/143 [==============================] - 8s 34ms/step - loss: 0.6931 - accuracy: 0.6484 - val_loss: 0.6931 - val_accuracy: 0.6484\n",
      "149/149 [==============================] - 2s 13ms/step\n",
      "gg\n",
      "143/143 [==============================] - 6s 26ms/step - loss: 0.6943 - accuracy: 0.5199 - val_loss: 0.6931 - val_accuracy: 0.5094\n",
      "149/149 [==============================] - 2s 9ms/step\n",
      "gg\n",
      "143/143 [==============================] - 6s 29ms/step - loss: 0.6931 - accuracy: 0.6484 - val_loss: 0.6931 - val_accuracy: 0.6484\n",
      "149/149 [==============================] - 2s 9ms/step\n",
      "gg\n",
      "143/143 [==============================] - 6s 29ms/step - loss: 0.6510 - accuracy: 0.6484 - val_loss: 0.6485 - val_accuracy: 0.6484\n",
      "149/149 [==============================] - 1s 8ms/step\n",
      "gg\n",
      "143/143 [==============================] - 6s 29ms/step - loss: 0.6931 - accuracy: 0.6484 - val_loss: 0.6931 - val_accuracy: 0.6484\n",
      "149/149 [==============================] - 2s 11ms/step\n",
      "gg\n",
      "143/143 [==============================] - 6s 29ms/step - loss: 0.6666 - accuracy: 0.6484 - val_loss: 0.6523 - val_accuracy: 0.6484\n",
      "149/149 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "iterations = 1 # number of iterations that we plan to perform for each pair of hidden_layer_af - output_layer_af\n",
    "dataframes = [pd.DataFrame() for _ in range(0, iterations)] # declare a list of empty dataframes to store the results of the iterations\n",
    "\n",
    "for df_index in range(0, iterations):\n",
    "    dataframes[df_index] = pd.DataFrame(columns = ['data_Dimension', 'Classes', 'Hidden_AF', 'TrainTest_Split', 'First_Hidden_Layer_Tensor_Count', 'Dropouts', 'Train_Accuracy', 'Test_Accuracy'])\n",
    "\n",
    "# results_df = pd.DataFrame(columns = ['data_Dimension', 'Classes', 'Hidden_AF', 'Output_AF', 'TrainTest_Split', 'First_Hidden_Layer_Tensor_Count', 'Dropouts', 'Train_Accuracy', 'Test_Accuracy'])\n",
    "\n",
    "Hidden_AF_list = ['relu', 'gelu', 'selu', 'sigmoid', 'tanh', 'softmax']\n",
    "# Output_AF_list = ['gelu', 'sigmoid']\n",
    "First_Hidden_Layer_Tensor_Count = 100\n",
    "TrainTest_Split = 0.25\n",
    "Dropouts = 0.3\n",
    "wt_init=2.2\n",
    "bias_init=0\n",
    "\n",
    "for df_index in range(0, iterations):\n",
    "    i = 0\n",
    "    for haf in range(0,len(Hidden_AF_list)):\n",
    "        encoded_dataframe, classes, Train_FEATURE_matrix, Test_FEATURE_matrix, Train_TARGET_matrix, Test_TARGET_matrix = buildDataSet (df, TrainTest_Split)\n",
    "        train_accuracy_score, test_accuracy_score = Study_Activation_Functions(Hidden_AF_list[haf], First_Hidden_Layer_Tensor_Count, Dropouts, classes, Train_FEATURE_matrix, Test_FEATURE_matrix, Train_TARGET_matrix, Test_TARGET_matrix,CustomWeight(), wt_init, bias_init)\n",
    "        dataframes[df_index].loc[i] = [encoded_dataframe.shape, classes, Hidden_AF_list[haf], TrainTest_Split, First_Hidden_Layer_Tensor_Count, Dropouts, np.round(train_accuracy_score,3), np.round(test_accuracy_score,3)]\n",
    "        i = i + 1\n",
    "    # model_.reset_states()\n",
    "    # reset_weights(model_)    \n",
    "     \n",
    "    # print(f\"dataframe {df_index + 1}:\")\n",
    "    # print(dataframes[df_index])\n",
    "    # print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_Dimension</th>\n",
       "      <th>Classes</th>\n",
       "      <th>Hidden_AF</th>\n",
       "      <th>TrainTest_Split</th>\n",
       "      <th>First_Hidden_Layer_Tensor_Count</th>\n",
       "      <th>Dropouts</th>\n",
       "      <th>Robust_Train_Accuracy</th>\n",
       "      <th>Robust_Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>selu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_Dimension  Classes Hidden_AF  TrainTest_Split  \\\n",
       "0    (19020, 11)        2      relu             0.25   \n",
       "2    (19020, 11)        2      selu             0.25   \n",
       "3    (19020, 11)        2   sigmoid             0.25   \n",
       "4    (19020, 11)        2      tanh             0.25   \n",
       "5    (19020, 11)        2   softmax             0.25   \n",
       "1    (19020, 11)        2      gelu             0.25   \n",
       "\n",
       "   First_Hidden_Layer_Tensor_Count  Dropouts  Robust_Train_Accuracy  \\\n",
       "0                              100       0.3                  0.648   \n",
       "2                              100       0.3                  0.648   \n",
       "3                              100       0.3                  0.648   \n",
       "4                              100       0.3                  0.648   \n",
       "5                              100       0.3                  0.648   \n",
       "1                              100       0.3                  0.516   \n",
       "\n",
       "   Robust_Test_Accuracy  \n",
       "0                 0.648  \n",
       "2                 0.648  \n",
       "3                 0.648  \n",
       "4                 0.648  \n",
       "5                 0.648  \n",
       "1                 0.509  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = dataframes[0]\n",
    "results_df = results_df.rename(columns={\"Train_Accuracy\": \"Robust_Train_Accuracy\", \"Test_Accuracy\": \"Robust_Test_Accuracy\"})\n",
    "for df_index in range(1, iterations):\n",
    "    results_df['Robust_Train_Accuracy'] = results_df['Robust_Train_Accuracy'] + dataframes[df_index]['Train_Accuracy']\n",
    "    results_df['Robust_Test_Accuracy'] = results_df['Robust_Test_Accuracy'] + dataframes[df_index]['Test_Accuracy']\n",
    "results_df['Robust_Train_Accuracy'] = round((results_df['Robust_Train_Accuracy'] / iterations),4)\n",
    "results_df['Robust_Test_Accuracy'] = round((results_df['Robust_Test_Accuracy'] / iterations),4)\n",
    "\n",
    "results_df.to_csv(\"results_df.csv\")\n",
    "results_df.sort_values(by = 'Robust_Test_Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
