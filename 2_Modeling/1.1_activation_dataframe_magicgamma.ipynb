{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from livelossplot import PlotLossesKeras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# set random seed globally\n",
    "my_seed = 21\n",
    "from numpy.random import seed\n",
    "seed(my_seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(my_seed) \n",
    "# tensorflow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC Gamma Telescope Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19020 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fLength    fWidth   fSize   fConc  fConc1     fAsym   fM3Long  \\\n",
       "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
       "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
       "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
       "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
       "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
       "...         ...       ...     ...     ...     ...       ...       ...   \n",
       "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
       "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
       "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
       "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
       "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
       "\n",
       "       fM3Trans   fAlpha     fDist class  \n",
       "0       -8.2027  40.0920   81.8828     g  \n",
       "1       -9.9574   6.3609  205.2610     g  \n",
       "2      -45.2160  76.9600  256.7880     g  \n",
       "3       -7.1513  10.4490  116.7370     g  \n",
       "4       21.8393   4.6480  356.4620     g  \n",
       "...         ...      ...       ...   ...  \n",
       "19015    2.8766   2.4229  106.8258     h  \n",
       "19016   -2.9632  86.7975  247.4560     h  \n",
       "19017   -9.4662  30.2987  256.5166     h  \n",
       "19018  -63.8389  84.6874  408.3166     h  \n",
       "19019   31.4755  52.7310  272.3174     h  \n",
       "\n",
       "[19020 rows x 11 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataframe from https://archive.ics.uci.edu/ml/datasets/magic+gamma+telescope\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data',\n",
    "                 names = ['fLength','fWidth','fSize','fConc','fConc1','fAsym','fM3Long','fM3Trans','fAlpha','fDist','class'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSet (dataframe, test_data_fraction):\n",
    "    # encoding the target column\n",
    "    le = LabelEncoder()\n",
    "    label = le.fit_transform(df['class'])\n",
    "    label\n",
    "\n",
    "    encoded_df = df.copy()\n",
    "    encoded_df.drop(\"class\", axis=1, inplace=True)\n",
    "    encoded_df[\"class\"] = label\n",
    "\n",
    "    # Set the total number of classes\n",
    "    nb_classes = len(encoded_df['class'].unique())\n",
    "\n",
    "    # Creating target and features\n",
    "    X = encoded_df.drop(['class'], axis=1)\n",
    "    y = encoded_df['class']\n",
    "\n",
    "    # scale the variables\n",
    "    sc = StandardScaler() \n",
    "    X_scaled = sc.fit_transform(X)\n",
    "\n",
    "    # Split into train and test set and normalize data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, test_size = test_data_fraction,stratify=y) #, random_state = 0)\n",
    "\n",
    "\n",
    "    return encoded_df, nb_classes, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
      "\n",
      "    fAlpha     fDist  class  \n",
      "0  40.0920   81.8828      0  \n",
      "1   6.3609  205.2610      0  \n",
      "2  76.9600  256.7880      0  \n",
      "3  10.4490  116.7370      0  \n",
      "4   4.6480  356.4620      0  \n",
      "\n",
      "(19020, 11)\n",
      "\n",
      "classes_in_dataset = 2\n",
      "\n",
      "X_train.shape = (15216, 10)\n",
      "X_test.shape = (3804, 10)\n",
      "y_train.shape = (15216,)\n",
      "y_test.shape = (3804,)\n"
     ]
    }
   ],
   "source": [
    "# build dataset on our dataframe\n",
    "encoded_dataframe, classes, Train_FEATURE_matrix, Test_FEATURE_matrix, Train_TARGET_matrix, Test_TARGET_matrix = buildDataSet (df, 0.2)\n",
    "\n",
    "print(encoded_dataframe.head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(encoded_dataframe.shape)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(f\"classes_in_dataset = {classes}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(f\"X_train.shape = {Train_FEATURE_matrix.shape}\")\n",
    "print(f\"X_test.shape = {Test_FEATURE_matrix.shape}\")\n",
    "print(f\"y_train.shape = {Train_TARGET_matrix.shape}\")\n",
    "print(f\"y_test.shape = {Test_TARGET_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSequentialModel(hidden_layers_activation, output_layer_activation, first_layer_node_count, dropout_fraction, nb_classes):\n",
    "    # Build a Sequential Model.\n",
    "    model = Sequential()\n",
    "    # model.add(Flatten(input_shape=(28, 28)))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(first_layer_node_count, kernel_initializer='normal', activation=hidden_layers_activation))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    model.add(Dense(first_layer_node_count*0.8, kernel_initializer='normal', activation=hidden_layers_activation))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    model.add(Dense(first_layer_node_count*0.6, kernel_initializer='normal', activation=hidden_layers_activation))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(nb_classes, activation=output_layer_activation))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional Activation Functions to test\n",
    "- Logistic regression hypothesis (Sigmoid)\n",
    "- Hyperbolic Tangent (tanh) # rescaled sigmoid to (-1, +1)\n",
    "- Rectified Linear Unit (ReLU)\n",
    "- Gaussian Error Linear Unit (GELU) # smoothed ReLU\n",
    "- Normalized Exponential Function (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Study_Activation_Functions(hidden_layers_activation, output_layer_activation, first_layer_node_count, dropout_fraction, classes, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # instantiate model\n",
    "    model = buildSequentialModel(hidden_layers_activation, output_layer_activation, first_layer_node_count, dropout_fraction, classes)\n",
    "    # compile model\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=5, verbose=0, validation_data=(X_test, y_test))\n",
    "\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)[1] \n",
    "\n",
    "    predicted_classes = np.argmax(model.predict(X_test), axis=-1)\n",
    "    correct_indices = np.nonzero(predicted_classes == y_test.values)[0]\n",
    "    incorrect_indices = np.nonzero(predicted_classes != y_test.values)[0]\n",
    "\n",
    "    return train_score, test_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_Dimension</th>\n",
       "      <th>Classes</th>\n",
       "      <th>Hidden_AF</th>\n",
       "      <th>Output_AF</th>\n",
       "      <th>TrainTest_Split</th>\n",
       "      <th>First_Hidden_Layer_Tensor_Count</th>\n",
       "      <th>Dropouts</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>gelu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>selu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>gelu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>softmax</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>softmax</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>selu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(19020, 11)</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_Dimension  Classes Hidden_AF Output_AF  TrainTest_Split  \\\n",
       "1     (19020, 11)        2      relu   sigmoid              0.2   \n",
       "3     (19020, 11)        2      gelu   sigmoid              0.2   \n",
       "5     (19020, 11)        2      selu   sigmoid              0.2   \n",
       "7     (19020, 11)        2   sigmoid   sigmoid              0.2   \n",
       "9     (19020, 11)        2      tanh   sigmoid              0.2   \n",
       "2     (19020, 11)        2      gelu      gelu              0.2   \n",
       "0     (19020, 11)        2      relu      gelu              0.2   \n",
       "10    (19020, 11)        2   softmax      gelu              0.2   \n",
       "11    (19020, 11)        2   softmax   sigmoid              0.2   \n",
       "8     (19020, 11)        2      tanh      gelu              0.2   \n",
       "4     (19020, 11)        2      selu      gelu              0.2   \n",
       "6     (19020, 11)        2   sigmoid      gelu              0.2   \n",
       "\n",
       "    First_Hidden_Layer_Tensor_Count  Dropouts  Train_Accuracy  Test_Accuracy  \n",
       "1                               100       0.3           0.868          0.870  \n",
       "3                               100       0.3           0.847          0.837  \n",
       "5                               100       0.3           0.834          0.831  \n",
       "7                               100       0.3           0.787          0.796  \n",
       "9                               100       0.3           0.791          0.793  \n",
       "2                               100       0.3           0.703          0.696  \n",
       "0                               100       0.3           0.685          0.689  \n",
       "10                              100       0.3           0.648          0.648  \n",
       "11                              100       0.3           0.648          0.648  \n",
       "8                               100       0.3           0.629          0.633  \n",
       "4                               100       0.3           0.528          0.534  \n",
       "6                               100       0.3           0.352          0.352  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results_df = pd.DataFrame(columns = ['Rows', 'Columns', 'Classes', 'Hidden_AF', 'Output_AF', 'Train-Test_Split', 'First_Hidden_Layer_Tensor', 'Dropouts', 'Train_Accuracy', 'Test_Accuracy'])\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['data_Dimension', 'Classes', 'Hidden_AF', 'Output_AF', 'TrainTest_Split', 'First_Hidden_Layer_Tensor_Count', 'Dropouts', 'Train_Accuracy', 'Test_Accuracy'])\n",
    "\n",
    "Hidden_AF_list = ['relu', 'gelu', 'selu', 'sigmoid', 'tanh', 'softmax']\n",
    "Output_AF_list = ['gelu', 'sigmoid']\n",
    "First_Hidden_Layer_Tensor_Count = 100\n",
    "TrainTest_Split = 0.2\n",
    "Dropouts = 0.3\n",
    "\n",
    "\n",
    "i = 0\n",
    "for haf in range(0,len(Hidden_AF_list)):\n",
    "    for oaf in range(0, len(Output_AF_list)):\n",
    "        encoded_dataframe, classes, Train_FEATURE_matrix, Test_FEATURE_matrix, Train_TARGET_matrix, Test_TARGET_matrix = buildDataSet (df, TrainTest_Split)\n",
    "        train_accuracy_score, test_accuracy_score = Study_Activation_Functions(Hidden_AF_list[haf], Output_AF_list[oaf], First_Hidden_Layer_Tensor_Count, Dropouts, classes, Train_FEATURE_matrix, Test_FEATURE_matrix, Train_TARGET_matrix, Test_TARGET_matrix)\n",
    "        results_df.loc[i] = [encoded_dataframe.shape, classes, Hidden_AF_list[haf], Output_AF_list[oaf], TrainTest_Split, First_Hidden_Layer_Tensor_Count, Dropouts, np.round(train_accuracy_score,3), np.round(test_accuracy_score,3)]\n",
    "        i = i + 1\n",
    "\n",
    "results_df.sort_values(by = 'Test_Accuracy', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
